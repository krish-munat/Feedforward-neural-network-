{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6284a8dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelBinarizer  \u001b[38;5;66;03m# For one-hot encoding labels\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report  \u001b[38;5;66;03m# To generate classification reports\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential   \u001b[38;5;66;03m# Sequential model for stacking layers\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense        \u001b[38;5;66;03m# Dense layers for fully connected neural network\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD      \u001b[38;5;66;03m# Stochastic Gradient Descent optimizer\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer  # For one-hot encoding labels\n",
    "from sklearn.metrics import classification_report  # To generate classification reports\n",
    "from tensorflow.keras.models import Sequential   # Sequential model for stacking layers\n",
    "from tensorflow.keras.layers import Dense        # Dense layers for fully connected neural network\n",
    "from tensorflow.keras.optimizers import SGD      # Stochastic Gradient Descent optimizer\n",
    "from tensorflow.keras.datasets import mnist      # MNIST dataset\n",
    "from tensorflow.keras import backend as K        # Backend for Keras (e.g., TensorFlow)\n",
    "import matplotlib.pyplot as plt                   # For plotting\n",
    "import numpy as np                               # For numerical operations\n",
    "import argparse                                  # For command-line arguments\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "\thelp=(\"path to the output loss/accuracy plot\"))  # Argument parser for specifying output path\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# grab the MNIST dataset\n",
    "print(\"[INFO] accessing MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()  # Load MNIST dataset\n",
    "\n",
    "# each image in the MNIST dataset is represented as a 28x28x1\n",
    "# image, but in order to apply a standard neural network we must\n",
    "# first \"flatten\" the image to be simple list of 28x28=784 pixels\n",
    "trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))  # Reshape training data\n",
    "testX = testX.reshape((testX.shape[0], 28 * 28 * 1))    # Reshape testing data\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0  # Normalize training data\n",
    "testX = testX.astype(\"float32\") / 255.0    # Normalize testing data\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()  # Initialize label binarizer\n",
    "trainY = lb.fit_transform(trainY)  # One-hot encode training labels\n",
    "testY = lb.transform(testY)        # One-hot encode testing labels\n",
    "\n",
    "# define the 784-256-128-10 architecture using Keras\n",
    "model = Sequential()  # Initialize a sequential model\n",
    "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))  # Add input layer with 256 units\n",
    "model.add(Dense(128, activation=\"sigmoid\"))  # Add hidden layer with 128 units\n",
    "model.add(Dense(10, activation=\"softmax\"))  # Add output layer with 10 units and softmax activation\n",
    "\n",
    "# train the model using SGD\n",
    "print(\"[INFO] training network...\")\n",
    "sgd = SGD(0.01)  # Initialize SGD optimizer with learning rate 0.01\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])  # Compile the model with categorical cross-entropy loss\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "\tepochs=100, batch_size=128)  # Train the model for 100 epochs with batch size 128\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=128)  # Generate predictions on test set\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1),\n",
    "\ttarget_names=[str(x) for x in lb.classes_]))  # Generate and print classification report\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")  # Set the style for the plot\n",
    "plt.figure()  # Create a new figure\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")  # Plot training loss\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")  # Plot validation loss\n",
    "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")  # Plot training accuracy\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")  # Plot validation accuracy\n",
    "plt.title(\"Training Loss and Accuracy\")  # Set plot title\n",
    "plt.xlabel(\"Epoch #\")  # Set x-axis label\n",
    "plt.ylabel(\"Loss/Accuracy\")  # Set y-axis label\n",
    "plt.legend()  # Add legend to the plot\n",
    "plt.savefig(args[\"output\"])  # Save the plot to the specified output path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
